{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff87e81e-cbed-49d2-a0d4-0ae4e273e3d3",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>Smart Substitute Spectrum: Elevate Your Plate, Nourish Your Well-being!</font>\n",
    "\n",
    "####  DSE 203 Project - Team Christopher Vanhook, Vaaruni Desai, Zufeshan Imran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a670adc-a212-48ac-bee2-b7ee105ee550",
   "metadata": {},
   "source": [
    "### Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9329a1d5-f8d9-41b9-a1d4-d1dfb32be401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import openai\n",
    "import psycopg2\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_dedupe\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.util import ngrams\n",
    "from fuzzywuzzy import process\n",
    "from neo4j import GraphDatabase\n",
    "from jsonpath_ng.ext import parse\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e2f14-3fe3-4101-af8d-f8a997d21c94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### All the required settings to run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d80848f-c471-435b-a353-2abbb0f36c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# portstemmer to get the stem of keywords\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# establishing connection to nourish_db \n",
    "connection = psycopg2.connect(\n",
    "        dbname='nourish',\n",
    "        user='v1desai@ucsd.edu',\n",
    "        password='emfQGcx3',\n",
    "        host='awesome-hw.sdsc.edu',\n",
    "        port=5432\n",
    "    )\n",
    "\n",
    "# requirements to connect to neo4j\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "\n",
    "# function to remove non-alpha data\n",
    "def clean_text(text):\n",
    "    text = re.sub('\\W+',' ', str(text))\n",
    "    return text.lower()\n",
    "\n",
    "# funtion to get the required data from nourish_db for comparison in future\n",
    "def get_experimental_table():\n",
    "    cur = connection.cursor()\n",
    "    exp_query = \"\"\"SELECT fdc_id, description FROM usda_2022_food_branded_experimental\"\"\"\n",
    "    cur.execute(exp_query)\n",
    "    records = cur.fetchall()\n",
    "    columns = [desc[0] for desc in cur.description]\n",
    "    cur.close()\n",
    "    \n",
    "    df_experimental = pd.DataFrame(records, columns = columns)\n",
    "    df_experimental.drop_duplicates(subset = 'description', keep = 'first', inplace = True)\n",
    "    df_experimental.reset_index(drop = True, inplace = True)\n",
    "    df_experimental['description'] = df_experimental.apply(lambda row :clean_text(row['description']), axis = 1)\n",
    "    return df_experimental\n",
    "\n",
    "# get the table and store it in a variable for future use\n",
    "df_experimental = get_experimental_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412b92d-028b-4b80-8ae8-bcb90f690b68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Loading json and csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f26b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the json data\n",
    "\n",
    "with open('ingredient_and_instructions.json') as file:\n",
    "    tasty_json_ingredients = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caddb6b9-4ab8-48c6-80e4-773e887654ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>calories</th>\n",
       "      <th>sugar</th>\n",
       "      <th>carbohydrates</th>\n",
       "      <th>fiber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homemade-cinnamon-rolls</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whipped-coffee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fluffy-perfect-pancakes</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tasty-101-cinnamon-rolls</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>healthy-banana-pancakes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       slug  protein   fat  calories  sugar  carbohydrates  \\\n",
       "0   homemade-cinnamon-rolls      7.0  21.0     479.0   24.0           63.0   \n",
       "1            whipped-coffee      0.0   0.0      69.0   18.0           18.0   \n",
       "2   fluffy-perfect-pancakes     36.0  50.0    1102.0   12.0          123.0   \n",
       "3  tasty-101-cinnamon-rolls      8.0  25.0     562.0   28.0           74.0   \n",
       "4   healthy-banana-pancakes      7.0   4.0     184.0    9.0           30.0   \n",
       "\n",
       "   fiber  \n",
       "0    1.0  \n",
       "1    0.0  \n",
       "2    3.0  \n",
       "3    1.0  \n",
       "4    4.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the csv file into a dataframe\n",
    "\n",
    "df_tasty_dishes = pd.read_csv('dishes.csv',usecols=['slug', 'protein', 'fat', 'calories', 'sugar', 'carbohydrates', 'fiber']) \n",
    "df_tasty_dishes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527e407-5e6a-4bc9-bda5-e701b3bb4cc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load in the unstructured data using jsonpath_ng library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471488a8-d664-4004-bd1d-2be58dfab5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstructured data\n",
    "\n",
    "jsonpath_expr = parse(\"$..['instructions']\")\n",
    "matches = [match.value for match in jsonpath_expr.find(tasty_json_ingredients)]\n",
    "\n",
    "text = []\n",
    "for i in range(len(matches)):\n",
    "    list_text = \" \".join(line['display_text'].strip() for line in matches[i])\n",
    "    text.append(list_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cb48e-59ba-4aa9-bb2d-8da8de0e7565",
   "metadata": {},
   "source": [
    "### Data transformation - Load the products, ingredients data using jsonpath_ng library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274efb9e-a641-42fd-9cf0-2dc44b69423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all products\n",
    "\n",
    "expr = parse(\"$\")\n",
    "list_products = [match.value.keys() for match in expr.find(tasty_json_ingredients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d682f60e-1ccb-4dbc-ba4b-4aeea2ed82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all ingredients from ingredient sections\n",
    "\n",
    "jsonpath_expr = parse(\"$..['ingredient_sections']\")\n",
    "matches = [match.value for match in jsonpath_expr.find(tasty_json_ingredients)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4479d9b5-ff03-4144-a2f8-50306dddc497",
   "metadata": {},
   "source": [
    "### Extracting list of ingredients per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d02444-7d42-4eea-b2be-d78f39cc25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting list of ingredients product by product\n",
    "\n",
    "ingredients = []\n",
    "ingredient_per_prod = []\n",
    "for products in matches:\n",
    "    for product in products:\n",
    "        ing_per_prod = product['ingredients']\n",
    "        for ing in ing_per_prod:\n",
    "            ingredient_per_prod.append(ing['name'])\n",
    "    ingredients.append(ingredient_per_prod)\n",
    "    ingredient_per_prod = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20f9a6c2-055b-4326-b4a0-b23d0066dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all metric_unit for each ingredient per product\n",
    "\n",
    "metric = []\n",
    "metric_per_prod = []\n",
    "for products in matches:\n",
    "    for product in products:\n",
    "        met_per_prod = product['ingredients']\n",
    "        for met in met_per_prod:\n",
    "            if met['metric_unit'] is not None:\n",
    "                metric_per_prod.append((met['metric_unit']['quantity'],met['metric_unit']['display']))\n",
    "            else:\n",
    "                metric_per_prod.append((None,None))\n",
    "    metric.append(metric_per_prod)\n",
    "    metric_per_prod = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d64ab-3c55-4483-b8fc-d486f336ccf6",
   "metadata": {},
   "source": [
    "### Loading the above data into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f035d0f-0717-4d1c-bdc2-b73ed9f6cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all data extracted from json file into pandas series\n",
    "\n",
    "col_products = pd.Series(list_products[0])\n",
    "col_ingredients = pd.Series(ingredients)\n",
    "col_metric_unit = pd.Series(metric)\n",
    "col_instructions = pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2f5fdd-3c6a-4600-ae46-212217de2bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>metric_unit</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homemade-cinnamon-rolls</td>\n",
       "      <td>[unsalted butter, whole milk, granulated sugar...</td>\n",
       "      <td>[(115, g), (480, mL), (100, g), (None, None), ...</td>\n",
       "      <td>Generously butter two disposable foil pie/cake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whipped-coffee</td>\n",
       "      <td>[hot water, sugar, instant coffee powder, milk...</td>\n",
       "      <td>[(28, g), (24, g), (12, g), (None, None), (Non...</td>\n",
       "      <td>Add the hot water, sugar, and instant coffee t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fluffy-perfect-pancakes</td>\n",
       "      <td>[flour, baking powder, milk, butter, egg yolks...</td>\n",
       "      <td>[(500, g), (None, None), (960, mL), (170, g), ...</td>\n",
       "      <td>Whisk together the flour and baking powder in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tasty-101-cinnamon-rolls</td>\n",
       "      <td>[whole milk, sugar, unsalted butter, active dr...</td>\n",
       "      <td>[(480, mL), (100, g), (None, None), (None, Non...</td>\n",
       "      <td>Make the dough: In a large bowl, whisk togethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>healthy-banana-pancakes</td>\n",
       "      <td>[ripe bananas, eggs, vanilla extract, quick-co...</td>\n",
       "      <td>[(None, None), (None, None), (None, None), (70...</td>\n",
       "      <td>Mash bananas in a large bowl until smooth. Mix...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   products  \\\n",
       "0   homemade-cinnamon-rolls   \n",
       "1            whipped-coffee   \n",
       "2   fluffy-perfect-pancakes   \n",
       "3  tasty-101-cinnamon-rolls   \n",
       "4   healthy-banana-pancakes   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [unsalted butter, whole milk, granulated sugar...   \n",
       "1  [hot water, sugar, instant coffee powder, milk...   \n",
       "2  [flour, baking powder, milk, butter, egg yolks...   \n",
       "3  [whole milk, sugar, unsalted butter, active dr...   \n",
       "4  [ripe bananas, eggs, vanilla extract, quick-co...   \n",
       "\n",
       "                                         metric_unit  \\\n",
       "0  [(115, g), (480, mL), (100, g), (None, None), ...   \n",
       "1  [(28, g), (24, g), (12, g), (None, None), (Non...   \n",
       "2  [(500, g), (None, None), (960, mL), (170, g), ...   \n",
       "3  [(480, mL), (100, g), (None, None), (None, Non...   \n",
       "4  [(None, None), (None, None), (None, None), (70...   \n",
       "\n",
       "                                        instructions  \n",
       "0  Generously butter two disposable foil pie/cake...  \n",
       "1  Add the hot water, sugar, and instant coffee t...  \n",
       "2  Whisk together the flour and baking powder in ...  \n",
       "3  Make the dough: In a large bowl, whisk togethe...  \n",
       "4  Mash bananas in a large bowl until smooth. Mix...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding each pandas series as dataframe columns\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['products'] = col_products\n",
    "df['ingredients'] = col_ingredients\n",
    "df['metric_unit'] = col_metric_unit\n",
    "df['instructions'] = col_instructions\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda25c8-70aa-4ec2-9520-32a04d7f5260",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Merging data using left join operation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1abaa7-2f24-4868-9d50-d5261f90b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the newly formed dataframe with the tasty_dishes dataframe that contains csv data\n",
    "\n",
    "df_products = df.merge(df_tasty_dishes,how='inner',left_on='products',right_on='slug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbfe841a-7830-4540-ab4c-e4ad5991100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data and dropping unnecessary columns and nulls\n",
    "\n",
    "df_products.drop('slug',axis=1,inplace=True)\n",
    "df_products.dropna(inplace = True)\n",
    "df_products.reset_index(inplace = True, drop = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e7857c-9c50-406b-a2af-1bcb823491e3",
   "metadata": {},
   "source": [
    "### Entity resolution \n",
    "**We're using the library 'pandas_dedupe' to cluster the products based on product names.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da64be28-4344-4cd6-854e-7e7f05b01c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_3328\\1111005996.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_final = pandas_dedupe.dedupe_dataframe(df_products,['products'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from dedupe_dataframe_learned_settings\n",
      "Clustering...\n",
      "# duplicate sets 2855\n"
     ]
    }
   ],
   "source": [
    "df_final = pandas_dedupe.dedupe_dataframe(df_products,['products'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6fdd6ec-aa78-4aab-a8d1-e67fe96ef211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the ingredients column back to a list (pandas_dedupe converts all columns into strings)\n",
    "\n",
    "df_final['ingredients'] = df_final.apply(lambda row : [ingredient.strip()[1:-1] for ingredient in row['ingredients'][1:-1].split(', ')], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc334da0-9c2d-4e4f-8caa-4c25e3558223",
   "metadata": {},
   "source": [
    "### Adding cluster-keywords to the dataframe to make it easier to access clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a1893f-342d-465b-8ef0-fe97bd86a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_keywords gets the stem of each word and returns the first 3 words based on the number of appearances\n",
    "\n",
    "def extract_keywords(products):\n",
    "    keywords = [ps.stem(prod) for prod in products.split('-')]\n",
    "    counter = collections.Counter(keywords)\n",
    "    return [word for word,count in counter.most_common()[:3]]\n",
    "\n",
    "# add_keywords adds the extract_keywords to the dataframe\n",
    "def add_keywords(products_df):\n",
    "    cluster_groups = df_final.groupby('cluster id')['products'].agg(list)\n",
    "    cluster_keywords_df = pd.DataFrame(index=cluster_groups.index)\n",
    "    cluster_keywords_df['cluster_keywords'] = cluster_groups.apply(lambda products_list: ', '.join(extract_keywords('-'.join(products_list))))\n",
    "    \n",
    "    # Merge the cluster_keywords back to the original dataframe\n",
    "    df= pd.merge(df_final, cluster_keywords_df, on='cluster id')\n",
    "    \n",
    "    # Display the resulting dataframe\n",
    "    df = df[['products','ingredients','metric_unit','instructions','calories','protein','fat','sugar','carbohydrates','fiber','cluster id','cluster_keywords']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9860154-0e5c-4d53-98c3-77ef47733a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the add_keywords funtion\n",
    "\n",
    "df = add_keywords(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ebd8c9-23f3-4a69-9db3-d5a58b19a1f7",
   "metadata": {},
   "source": [
    "### Funtion to add nourish_db data into the dataframe if the cluster keywords match the product names in nourish_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68b06089-4525-44fd-b375-924acaa999c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_usda_rows(df, df_experimental, cluster_id):\n",
    "    clus_key = df.groupby('cluster id').get_group(cluster_id)['cluster_keywords']\n",
    "    matches = process.extract(clus_key.values[0], df_experimental['description'],scorer=fuzz.token_sort_ratio)\n",
    "    threshold = 95\n",
    "    filtered_matches = [match for match in matches if match[1] >= threshold]\n",
    "    fdc_to_match = []\n",
    "    # Extract rows based on the filtered matches\n",
    "    for match in filtered_matches:\n",
    "        index = match[2]\n",
    "        matched_row = df_experimental.iloc[index]\n",
    "        fdc_to_match.append(matched_row.fdc_id)\n",
    "    if len(fdc_to_match)>0:\n",
    "        fdc_to_match = tuple(fdc_to_match)\n",
    "        sql_query = f\"\"\"SELECT t1.fdc_id, t1.description, t2.amount, t3.name, t3.unit_name, t4.ingredients \\\n",
    "        FROM usda_2022_food_branded_experimental t1 \\\n",
    "        LEFT JOIN usda_2022_branded_food_nutrients t2 ON t1.fdc_id = t2.fdc_id \\\n",
    "        LEFT JOIN usda_2022_branded_food_product t4 ON t1.fdc_id = t4.fdc_id \\\n",
    "        LEFT JOIN usda_2022_nutrient_master t3 ON t2.nutrient_id = t3.id \\\n",
    "        WHERE t1.fdc_id IN {fdc_to_match}\"\"\"\n",
    "        \n",
    "        cur = connection.cursor()\n",
    "        cur.execute(sql_query)\n",
    "        records = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]\n",
    "        cur.close()\n",
    "        records_df = pd.DataFrame(records, columns = columns)\n",
    "        for fdc in fdc_to_match:\n",
    "            new_df = records_df.groupby('fdc_id').get_group(fdc)\n",
    "            new_row_append = pd.Series([new_df['description'].values[0].lower(), \\\n",
    "                                re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\",new_df.ingredients.values[0].lower()), \\\n",
    "                                None, \\\n",
    "                                None, \\\n",
    "                               float(new_df[new_df['name'] == 'Energy']['amount'].values[0]), \\\n",
    "                               float(new_df[new_df['name'] == 'Protein']['amount'].values[0]), \\\n",
    "                               float(new_df[new_df['name'] == 'Total lipid (fat)']['amount'].values[0]), \\\n",
    "                               float(new_df[new_df['name'] == 'Sugars, Total']['amount'].values[0]), \\\n",
    "                               float(new_df[new_df['name'] == 'Carbohydrate, by difference']['amount'].values[0]), \\\n",
    "                               float(new_df[new_df['name'] == 'Fiber, total dietary']['amount'].values[0]), \\\n",
    "                               cluster_id, \\\n",
    "                               clus_key[0]], index=df.columns)\n",
    "            df = pd.concat([df, pd.DataFrame([new_row_append], columns=df.columns)], ignore_index=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No match found, records not inserted\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab7f02-6238-48dc-99c5-9f882cc85280",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create neo4j graph using the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6144835b-e814-4eac-9072-60c7b0b542fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(tx, cluster_id, cluster_keywords, product_name, ingredients, instructions, protein, fat, calories, sugar, carbohydrates, fiber):\n",
    "    protein = float(protein)\n",
    "    fat = float(fat)\n",
    "    calories = float(calories)\n",
    "    sugar = float(sugar)\n",
    "    carbohydrates = float(carbohydrates)\n",
    "    fiber = float(fiber)\n",
    "    # create Cluster node\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (c:Cluster {name: $cluster_id, keywords: $cluster_keywords})\n",
    "    \"\"\", cluster_id=cluster_id, cluster_keywords=cluster_keywords)\n",
    "\n",
    "    # create pRODUCT node\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (p:Product {name: $product_name, protein: $protein, fat: $fat,\n",
    "                          calories: $calories, sugar: $sugar, carbohydrates: $carbohydrates, fiber: $fiber})\n",
    "    \"\"\", product_name=product_name, protein=protein, fat=fat, calories=calories, sugar=sugar, carbohydrates=carbohydrates, fiber=fiber)\n",
    "    \n",
    "    # create HAS_PRODUCTS relationships between cluster and Product\n",
    "    if product_name:\n",
    "        tx.run(\"\"\"MATCH (c:Cluster {name: $cluster_id})\n",
    "                  MATCH (p:Product {name: $product_name})\n",
    "                  MERGE (c)-[:HAS_PRODUCTS]->(p)\n",
    "               \"\"\", cluster_id=cluster_id, product_name=product_name)\n",
    "            \n",
    "    # create Ingredient nodes\n",
    "    for ingredient in ingredients:\n",
    "        if ingredient:\n",
    "            tx.run(\"\"\"\n",
    "                MERGE (i:Ingredient {name: $ingredient})\n",
    "            \"\"\", ingredient=ingredient)\n",
    "\n",
    "    # create CONTAINS relationships between Product and Ingredient\n",
    "    for ingredient in ingredients:\n",
    "        if ingredient:\n",
    "            tx.run(\"\"\"\n",
    "                MATCH (p:Product {name: $product_name})\n",
    "                MATCH (i:Ingredient {name: $ingredient})\n",
    "                MERGE (p)-[:CONTAINS]->(i)\n",
    "            \"\"\", product_name=product_name, ingredient=ingredient) \n",
    "\n",
    "    # create Instruction nodes\n",
    "    if instructions:\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (j:Instructions {instructions: $instructions})\n",
    "        \"\"\", instructions=instructions)\n",
    "    # create HAS_INSTRUCTIONS relationships between Product and Ingredient\n",
    "        tx.run(\"\"\"\n",
    "                MATCH (p:Product {name: $product_name})\n",
    "                MATCH (j:Instructions {instructions: $instructions})\n",
    "                MERGE (p)-[:HAS_INSTRUCTIONS]->(j)\n",
    "            \"\"\", product_name=product_name, instructions=instructions)\n",
    "        \n",
    "# connect to the database and run the transaction\n",
    "with GraphDatabase.driver(uri, auth=(username, password)) as driver:\n",
    "    with driver.session() as session:\n",
    "        for index, row in df.iterrows():\n",
    "            session.execute_write(create_graph,\n",
    "                                  row['cluster id'],\n",
    "                                  row['cluster_keywords'],\n",
    "                                  row['products'],\n",
    "                                  row['ingredients'],\n",
    "                                  row['instructions'],\n",
    "                                  row['protein'],\n",
    "                                  row['fat'],\n",
    "                                  row['calories'],\n",
    "                                  row['sugar'],\n",
    "                                  row['carbohydrates'],\n",
    "                                  row['fiber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cf931-a6e7-43d4-b47a-2e7d46295aca",
   "metadata": {},
   "source": [
    "### Queries to run on the neo4j graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e6e615e-129c-4b8e-9cf8-02df33f303c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run the query provided\n",
    "\n",
    "def run_cypher_query(query):\n",
    "    with GraphDatabase.driver(uri, auth=(username, password)) as driver:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            return result.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b4459-7383-42f1-a8ca-b77ad99bacee",
   "metadata": {},
   "source": [
    "#### Query 1 : \"I have vegan margarine, soy milk, sunflower oil, plain flour, caster sugar, baking powder, salt at home. Can you suggest me a quick recipe to make a dish out of this?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a028d-7b90-413e-bc8e-1228de6cb210",
   "metadata": {},
   "source": [
    "##### Function give_recipe_for_ingredients \n",
    "- searches for products that contain all the ingredients provided by the user\n",
    "- sorts the products based on number of sentences in the instructions\n",
    "- returns the recipe with least number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1dd52786-69ad-43fe-a4cc-06136367ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_recipe_for_ingredients(list_of_ingredients):\n",
    "    #graph_query - \"MATCH (p:Product)-[:CONTAINS]->(i:Ingredient) WITH p, COLLECT(i.name) AS productIngredients WHERE ALL(i IN ['vegan margarine', 'soy milk', 'sunflower oil', 'plain flour', 'caster sugar', 'baking powder', 'salt'] WHERE i IN productIngredients) MATCH (p)-[:HAS_INSTRUCTIONS]->(instr) RETURN p, instr\"\n",
    "    query3 = f\"\"\"MATCH (p:Product)-[:CONTAINS]->(i:Ingredient) \n",
    "            WITH p, COLLECT(i.name) AS productIngredients \n",
    "            WHERE ALL(i IN {list_of_ingredients} WHERE i IN productIngredients) \n",
    "            MATCH (p)-[:HAS_INSTRUCTIONS]->(instr) \n",
    "            RETURN p.name AS productName, instr.instructions, size(apoc.text.split(instr.instructions, \"\\.\")) AS numsentences \n",
    "            ORDER BY numsentences ASC LIMIT 1\n",
    "            \"\"\"\n",
    "    result3 = run_cypher_query(query3)\n",
    "    print(f\"With the ingredients provided, you can make {(' ').join(result3[0]['productName'].split('-')).upper()}.\\nThese are the instructions to prepare - \\n{result3[0]['instr.instructions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "796e840c-5069-4ffd-a0e0-2f51360f06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the ingredients provided, you can make VEGAN DOUGHNUTS.\n",
      "These are the instructions to prepare - \n",
      "gently melt the butter over a low-medium heat. add milk and 2 tablespoons of sunflower oil and mix together. once combined, take off the heat and set aside. in a separate bowl, combine the flour, half of the sugar, baking powder and salt with a fork. make a well in the center and pour in the butter mixture. combine gradually until a thick dough forms. using your hands, roll dough into little flat balls and with your thumb, press a hole in the center of each doughnut. (you may need to flour your hands for this part to avoid getting sticky!) heat up oil in a pan. to know when it's hot enough, fry a little bit of bread in the oil. if it goes brown and floats to the top, in 45-50 seconds the oil will be ready! gently lay the doughnuts into the oil using a spatula. fry for about 3-5 minutes on each side, until golden brown. transfer the doughnuts onto some tissue paper to soak up any excess oil. roll the doughnut into a bowl of the remaining half of sugar. enjoy!\n"
     ]
    }
   ],
   "source": [
    "list_of_ingredients = ['vegan margarine', 'soy milk', 'sunflower oil', 'plain flour', 'caster sugar', 'baking powder', 'salt']\n",
    "give_recipe_for_ingredients(list_of_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffff9d5-3695-48c8-aec5-a999c77b395c",
   "metadata": {},
   "source": [
    "#### Query 2 : \"I am a diabetes patient. Help me make some coffee while keeping my diabetes in mind\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4ea72-0e48-4f58-9032-38b669961f0c",
   "metadata": {},
   "source": [
    "##### Function food_for_condition \n",
    "- searches for clusters with keywords that contain the product_to_make\n",
    "- for all the products under each cluster, removes the ingredient that the user needs to avoid based on the given condition\n",
    "- for example - A diabetic patient needs to avoid sugar/alcohol\n",
    "- sorts the products in ascending order based on calories\n",
    "- gives the user option to choose between the 3 healthiest products\n",
    "- provides the user with ingredients to use and instructions to make the chosen product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd62bea5-95d5-4e3e-8092-c4bac506ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_for_condition (prod_to_make, user_query, food_to_avoid_file):\n",
    "\n",
    "    #get the food to avoid data\n",
    "    food_to_avoid = pd.read_csv(food_to_avoid_file, delimiter = ';')\n",
    "\n",
    "    #from the user query fetch the condition mentioned\n",
    "    for condition in food_to_avoid['Condition']:\n",
    "        if condition.lower() in user_query:\n",
    "            condition_to_consider = condition\n",
    "            \n",
    "    #search_keywords - food items to avoid for the given condition\n",
    "    search_keywords = food_to_avoid[food_to_avoid['Condition']==condition_to_consider]['food_to_avoid'].values[0].split(',')\n",
    "\n",
    "    #graph_query - \"WITH ['sugar','alcohol'] AS subs  MATCH (n:Cluster)  WHERE n.keywords CONTAINS 'coffe'  WITH n as cluster, subs  MATCH (cluster)-[:HAS_PRODUCTS]->(p:Product)  MATCH (p)-[:HAS_INSTRUCTIONS]->(instr:Instructions)  MATCH (p)-[:CONTAINS]->(i:Ingredient)   WHERE p.name CONTAINS 'coffe'   AND NOT ANY(word IN subs WHERE i.name CONTAINS word)  RETURN p, instr, COLLECT(i) ORDER BY p.calories ASC  LIMIT 3\"\n",
    "    #Cypher query to fetch low calorie product requested by user\n",
    "    query2 = f\"\"\"WITH {search_keywords} AS subs \n",
    "                MATCH (n:Cluster) \n",
    "                WHERE n.keywords CONTAINS '{prod_to_make}' \n",
    "                WITH n as cluster, subs \n",
    "                MATCH (cluster)-[:HAS_PRODUCTS]->(p:Product) \n",
    "                MATCH (p)-[:HAS_INSTRUCTIONS]->(instr:Instructions) \n",
    "                MATCH (p)-[:CONTAINS]->(i:Ingredient)  \n",
    "                WHERE p.name CONTAINS '{prod_to_make}'  \n",
    "                AND NOT ANY(word IN subs WHERE i.name CONTAINS word) \n",
    "                RETURN p.name as Product, instr.instructions AS instructions, COLLECT(i.name) as ingredients, p.calories AS calories \n",
    "                ORDER BY calories ASC \n",
    "                LIMIT 3\n",
    "                \"\"\"\n",
    "    result3 = run_cypher_query(query2)\n",
    "    \n",
    "    #Provide the user with 3 options of the product with least calories\n",
    "    recipe = input(f\"I have {len(result3)} recipes which are less in calories. Please pick one recipe among {(', ').join([result3[i]['Product'] for i in range(len(result3))])}\\n\\n\")\n",
    "\n",
    "    #format the requested recipe to search among the result\n",
    "    input_string = ('-').join(recipe.split(' ')).lower()\n",
    "\n",
    "    #print the ingredients and instructions for the requested recipe\n",
    "    for r in result3:\n",
    "        if r['Product'] == input_string:\n",
    "            for key in search_keywords:\n",
    "                if key in r['instructions']:\n",
    "                    r['instructions'] = r['instructions'].replace(f\"{key}, \", '')\n",
    "            print(f\"\\nIngredients to use : {r['ingredients']}\\n\\nInstructions to make {input_string} - {r['instructions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42219b5c-153b-4883-a2b4-393019d840b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "I have 3 recipes which are less in calories. Please pick one recipe among dalgona-coffee, whipped-coffee, cinnamon-coffee\n",
      "\n",
      " dalgona coffee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ingredients to use : ['milk', 'instant coffee', 'hot water']\n",
      "\n",
      "Instructions to make dalgona-coffee - add coffee, and water into a bowl or cup, and whip until it reaches a meringue like consistency! take a cup of milk & spoon whipped coffee on it and enjoy!\n"
     ]
    }
   ],
   "source": [
    "prod_to_make = ps.stem('Coffee')\n",
    "user_query = \"I am a diabetes patient. Help me make some coffee while keeping my diabetes in mind\"\n",
    "food_for_condition (prod_to_make, user_query, 'Disease_foods_to_avoid_no_names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e56f6-caf0-40c6-90ee-85231170a9fa",
   "metadata": {},
   "source": [
    "#### Query 3 : \"I want to make Healthy Pancakes. Can you give me a recipe?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c236ce7-7584-4476-82e6-0b8456a16a99",
   "metadata": {},
   "source": [
    "##### Function give_healthy_recipe \n",
    "- searches for cluster_keywords that contain the product provided by the user\n",
    "-  gets the products under these clusters that contain the search_substring\n",
    "-  sorts them in ascending order based on calories\n",
    "-  returns the 3 most healthiest recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb6dd447-3654-4e38-8035-533376c91d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to provide the user with healthiest recipe of the asked product\n",
    "def give_healthy_recipe(product):\n",
    "\n",
    "    # search substring - stem of the product\n",
    "    search_substring = ps.stem(product)\n",
    "\n",
    "    # query to run\n",
    "    #Graph_Query - \"MATCH (n:Cluster) WHERE n.keywords CONTAINS 'pancak' WITH n as cluster MATCH (cluster)-[:HAS_PRODUCTS]->(p:Product) MATCH (p)-[:HAS_INSTRUCTIONS]->(instr:Instructions)  MATCH (p)-[:CONTAINS]->(i:Ingredient)  RETURN p, instr, COLLECT(i) as ingredient\"\n",
    "    query1 = f\"\"\"MATCH (n:Cluster) \n",
    "                WHERE n.keywords CONTAINS '{search_substring}' \n",
    "                WITH n as cluster \n",
    "                MATCH (cluster)-[:HAS_PRODUCTS]->(p:Product) \n",
    "                MATCH (p)-[:HAS_INSTRUCTIONS]->(instr:Instructions) \n",
    "                MATCH (p)-[:CONTAINS]->(i:Ingredient) \n",
    "                WHERE p.name CONTAINS '{search_substring}' \n",
    "                RETURN p.name as Product, instr.instructions AS instructions, COLLECT(i.name) as ingredients, p.calories AS calories \n",
    "                ORDER BY calories ASC \n",
    "                LIMIT 3\n",
    "                \"\"\"\n",
    "    clusters_data = run_cypher_query(f\"MATCH (n:Cluster) WHERE n.keywords CONTAINS '{search_substring}' WITH n as cluster MATCH (cluster)-[:HAS_PRODUCTS]->(p:Product) MATCH (p)-[:HAS_INSTRUCTIONS]->(instr:Instructions) MATCH (p)-[:CONTAINS]->(i:Ingredient) WHERE p.name CONTAINS '{search_substring}' RETURN p.name as Product, instr.instructions AS instructions, COLLECT(i.name) as ingredients, p.calories AS calories ORDER BY calories ASC LIMIT 3\")\n",
    "    return clusters_data, search_substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50ef902a-fd85-4980-a787-1bc2b3d2868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function and store clusters_data and search_substring into variables\n",
    "\n",
    "clusters_data, search_substring = give_healthy_recipe('Pancake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41ef3851-a6f0-47bf-826a-8fbd3baf1478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'blueberry', 'butter', 'cinnamon', 'eggs', 'flour', 'maple syrup', 'milk', 'topping of your choice', 'vanilla']\n"
     ]
    }
   ],
   "source": [
    "# remove the ingredients that are similar to each other using fuzzywuzzy library\n",
    "\n",
    "ingredients = sorted(list(set([ing for i in clusters_data for ing in i['ingredients']])))\n",
    "for i in ingredients:\n",
    "    for j in ingredients:\n",
    "        ratio = fuzz.ratio(i,j)\n",
    "        if ratio>65 and i!=j:\n",
    "            ingredients.remove(j)\n",
    "\n",
    "print(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3869ee08-605d-47d6-a286-5c7a432978d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blend all ingredients in a blender until completely combined. divide among all the cups of a greased muffin tin, cups will be about  1/3  full. bake at 400degf (200degc) for 13-15 minutes. pancakes will puff up super big, then deflate when you remove them from the oven. fill with whatever you want--fresh fruit and syrup, bacon and eggs, sausage, or jam and whipped cream. enjoy!',\n",
       " 'in a large bowl, mash the bananas until they reach a liquid state. whisk in the eggs. heat butter or oil in a large skillet over medium heat. pour batter into the warm skillet to cook. garnish with desired number of blueberries. after about a minute and a half (or until golden) flip to finish cooking. allow to cool for a minute. serve warm. enjoy!',\n",
       " 'in a bowl, mash the banana with a fork. add eggs and cinnamon. mix until combined. heat a nonstick skillet over medium heat. add a spoonful of batter and cook for 3-4 minutes, then flip and cook for an additional 3-4 minutes. serve with maple syrup or honey. enjoy!']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the instructions for the 3 healthiest products\n",
    "\n",
    "instructions = [i['instructions'] for i in clusters_data]\n",
    "instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c777cd1-46d2-48a0-a24b-62688d7cb33f",
   "metadata": {},
   "source": [
    "##### Function summarize_instructions\n",
    "- uses openai to summarize the given instructions\n",
    "- returns the summarized instructions to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10482387-8276-473d-b835-b7d5f70d5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_instructions uses openai to summarize the unstructured data (instructions) to provide to the user\n",
    "\n",
    "def summarize_instructions(search_substring, instructions, ingredients):\n",
    "    openai.api_key = \"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\" \n",
    "    \n",
    "    prompt = \"\"\" Given the following instructions, ingredients and product to make, PLEASE summarize the instructions while STRICTLY following these rules\n",
    "    1. Please get me a summary of the quickest of the recipes, where the instructions do NOT repeat any steps.\n",
    "    2. Please include as many ingredients as possible in the instructions.\n",
    "    3. DO NOT create fictious data.\n",
    "    4. The output content should be in text format.\n",
    "    5. If you will be unable to output within the token limit, please DO NOT include that entry in the response. \"\"\"\n",
    "\n",
    "    #call gpt-3.5-turbo to extract relations\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that gives the summarized instructions of the given recipes who does NOT repeat any steps\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}, instructions:{instructions}, ingredients: {ingredients}, product_to_make: {search_substring}\"}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024 )\n",
    "    #get the response\n",
    "    print(f\"Ingredients required - {ingredients}\\nInstructions to prepare - {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "036a9ddf-224a-40cf-94a5-2cb1e01ebb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients required - ['banana', 'blueberry', 'butter', 'cinnamon', 'eggs', 'flour', 'maple syrup', 'milk', 'topping of your choice', 'vanilla']\n",
      "Instructions to prepare - To make pancakes, start by mashing the banana in a large bowl until it reaches a liquid state. Whisk in the eggs and add cinnamon. Heat butter in a large skillet over medium heat. Pour the batter into the warm skillet and garnish with blueberries. Cook for about a minute and a half or until golden, then flip to finish cooking. Allow to cool for a minute before serving warm with maple syrup or your choice of topping. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "summarize_instructions(search_substring, instructions, ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a8c6f-e01e-4fea-9e09-0e345be6719b",
   "metadata": {},
   "source": [
    "#### Query 4 - \"Please give me the vegan substitute of healthier chicken alfredo pasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81aebdb-417c-42fa-b519-b3bcddcc3922",
   "metadata": {},
   "source": [
    "##### Function get_vegan_recipe \n",
    "- gets the vegan substitutes data\n",
    "- searches for non-vegan-product in the products\n",
    "- gets the ingredient list and instructions for the non-vegan product\n",
    "- using the vegan substitutes data, replaces the non-vegan ingredients with vegan ingredients\n",
    "- returns the instructions for the new vegan product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a80a4c38-4425-43b2-a573-b08ba1b391ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vegan_recipe(non_veg_prod_name, vegan_csv_file):\n",
    "    #dictionary for substitutes (non_veg:veg)\n",
    "    subs = {}\n",
    "    \n",
    "    #read csv file\n",
    "    vegan_data = pd.read_csv(vegan_csv_file, delimiter = ';')\n",
    "    #convert Vegan_Ingredient string to list\n",
    "    vegan_data['Vegan_Ingredient'] = vegan_data.apply(lambda row : [x for x in row['Vegan_Ingredient'][1:-1].split(', ')], axis =1)\n",
    "\n",
    "    #graph_query - \"MATCH(p:Product)-[:CONTAINS]->(i:Ingredient) MATCH (p)-[:HAS_INSTRUCTIONS]->(j:Instructions) WHERE p.name = 'healthier-chicken-alfredo-pasta' RETURN p, COLLECT(i), j\"\n",
    "    #cypher query to match the product and return recipe and ingredients\n",
    "    query4 = f\"\"\"MATCH(p:Product)-[:CONTAINS]->(i:Ingredient) \n",
    "                MATCH (p)-[:HAS_INSTRUCTIONS]->(j:Instructions) \n",
    "                WHERE p.name = '{non_veg_prod_name}' \n",
    "                RETURN p.name, COLLECT(i.name) AS list_ingredients, j.instructions AS recipe\n",
    "                \"\"\"\n",
    "    result4 = run_cypher_query(query4)\n",
    "\n",
    "    #get substitutes for each non vegan ingredient in the recipe\n",
    "    for id,i in enumerate(result4[0]['list_ingredients']):\n",
    "        match = process.extract(i,vegan_data['Non_Vegan_Ingredient'])\n",
    "        for mtch in match:\n",
    "           if mtch[1]>85:\n",
    "               vegan_item = vegan_data[vegan_data['Non_Vegan_Ingredient']==mtch[0]]['Vegan_Ingredient'].values[0][0]\n",
    "               subs[mtch[0]]= vegan_item\n",
    "\n",
    "    #replace each non vegan ingredient in the recipe with its vegan substitute\n",
    "    for k,v in subs.items():\n",
    "        result4[0]['recipe'] = result4[0]['recipe'].replace(k,v)\n",
    "    return result4[0]['recipe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd1e5b4e-a5db-4c78-b26c-75a6b0120723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe to make the vegan version of chicken alfredo pasta is - \n",
      "\n",
      "heat the olive oil over a skillet and add tofu. season with salt and pepper, and cook 5-8 minutes, or until no longer pink. remove the tofu from the pan and set aside. in the same pan, add the garlic and saute for one minute over medium heat. sprinkle the flour over the garlic and slowly add in the tofu stock. quickly stir to avoid lumps. add in the skim oat milk, stir ,and allow to reach a boil to thicken sauce. season with salt and pepper. once the sauce is thickened, add in the spinach and stir until wilted. remove from heat and add in the cooked penne, tofu, and cashew cheese. stir to coat. top with fresh cashew cheese. enjoy!\n"
     ]
    }
   ],
   "source": [
    "vegan_recipe = get_vegan_recipe('healthier-chicken-alfredo-pasta', 'vegan_substitutes.csv')\n",
    "print(f\"Recipe to make the vegan version of chicken alfredo pasta is - \\n\\n{vegan_recipe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e111f12-886f-4778-a733-fdc42f4d61b6",
   "metadata": {},
   "source": [
    "#### Query 5 - \"I'm craving for something delicious, give me options for heart-disease-friendly recipes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bd7cb-eca5-4ecd-988a-b6971e07f394",
   "metadata": {},
   "source": [
    "##### Function get_recipes_for_health_condition\n",
    "- gets the list food items to be avoided by a user with given health condition\n",
    "- unwinds the list of food items\n",
    "- checks for products that don't contain any of the items that need to be avoided\n",
    "- groups the products based on the number of duplicate records\n",
    "- returns the recipes of the products who have duplicate number of records = the length of the food items to avoid list\n",
    "- orders data by fiber content since fiber is good for all health conditions\n",
    "- returns the top 5 recipes to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a740ab92-80d5-45e2-bed4-74e824d23074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipes_for_health_condition (condition,health_condition_file):\n",
    "\n",
    "    #read csv file specifying health condition and food to avoid for the condition\n",
    "    health_condition_df = pd.read_csv(health_condition_file, delimiter = ';')\n",
    "\n",
    "    #get the list of food items to avoid for the condition\n",
    "    ingredients_to_remove = health_condition_df[health_condition_df['Condition']==condition]['food_to_avoid'].to_list()[0].split(', ')\n",
    "\n",
    "    #graph_query - \"UNWIND ['butter', 'salt', 'oil', 'ghee', 'avocado', 'beef'] AS x  WITH x, size(['butter', 'salt', 'oil', 'ghee', 'avocado', 'beef']) AS no_of_items  MATCH (p:Product)-[:CONTAINS]->(ing:Ingredient)  MATCH (p:Product)-[:HAS_INSTRUCTIONS]->(ins:Instructions)  WITH COLLECT(ing) AS ing_nodes, COLLECT(ing.name) as ingredients, ins,p,x,no_of_items  WHERE NOT ANY(ingredient IN ingredients WHERE ingredient CONTAINS x)  WITH COUNT(p) AS pcount,p AS product, ing_nodes,ingredients, ins, no_of_items  WHERE no_of_items-pcount=0  RETURN product,ing_nodes,ins ORDER BY product.fiber DESC, product.calories ASC  LIMIT 5\"\n",
    "    #frame cypher query to get all products which don't contain any of the food items listed above\n",
    "    query5 = f\"\"\"UNWIND {ingredients_to_remove} AS x \n",
    "                WITH x, size({ingredients_to_remove}) AS no_of_items \n",
    "                MATCH (p:Product)-[:CONTAINS]->(ing:Ingredient) \n",
    "                MATCH (p:Product)-[:HAS_INSTRUCTIONS]->(ins:Instructions) \n",
    "                WITH COLLECT(ing.name) as ingredients, ins,p,x,no_of_items \n",
    "                WHERE NOT ANY(ingredient IN ingredients WHERE ingredient CONTAINS x) \n",
    "                WITH COUNT(p.name) AS pcount,p.name AS product, ingredients, ins.instructions AS instructions,p.calories AS calories, p.carbohydrates AS carbs, p.sugar AS total_sugar, p.fat AS fat, p.protein AS protein, p.fiber AS fiber, no_of_items \n",
    "                WHERE no_of_items-pcount=0 \n",
    "                RETURN product,ingredients,instructions,calories,carbs,total_sugar,protein,fiber \n",
    "                ORDER BY fiber DESC, calories ASC \n",
    "                LIMIT 5\n",
    "                \"\"\"\n",
    "    #run the cypher query\n",
    "    result5 = run_cypher_query(query5)\n",
    "\n",
    "    #return the result\n",
    "    return result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f167d40a-a857-4506-a17f-5d9ee1313827",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_for_health_condition = pd.DataFrame(get_recipes_for_health_condition ('Heart Disease','Disease_foods_to_avoid_no_names.csv'))\n",
    "recipes_for_health_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee10bf-b0aa-4250-803c-09259b916dbc",
   "metadata": {},
   "source": [
    "#### Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d0b06-3f49-447e-a3dc-98fa8280c5f1",
   "metadata": {},
   "source": [
    "Our current knowledge graph also leads into potential future work. \n",
    "The current average food cost, per patient, per day in a hospital is $268. \n",
    "This process requires a dietician to ensure that every patients needs are nutritionally met. \n",
    "Expanding upon our current idea, just as AI is beginning to be utilized in provisioning patient profiles for medication dosage, AI can be utilized to ensure patients are able to enjoy food and have their nutritional needs met at a cost cut to the healthcare industry.\n",
    "\n",
    "- Use metric-unit data to incorporate exact measurements of each ingredient\n",
    "- Use more advanced techniques to do entity resolution (for eg - blocking techniques, entity matching, clustering)\n",
    "- Usage of food_to_avoid data from valid sources like hospitals to give better recommendations to the user\n",
    "- Improve suggestions by expanding food nutrition profile\n",
    "- Use of data/knowledge graph by popular food logging applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
